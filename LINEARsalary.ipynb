{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Analyze Salary with Linear Regression\nPython Automation; Scott Schmidt; Illinois State University\n\n## Introduction\n1. The dataset will have two columns of data which are years and salary. \n2. Split the data using 75% training and 25% testing. \n3. Calculate Covariance and Variance to find the coefficients. \n4. Evaluate the model performance using Root Mean Square Error (RMSE).\n\nThis assignment is very valuable coming from soneone who passed a first round Python Data Science interview at a fortune100. This verifies that one understands all the imports by doing them manually by hand. Often times, imports can weaken ones understanding because the human will not understand the entire process.","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:00:20.938476Z","iopub.execute_input":"2022-02-23T19:00:20.938748Z","iopub.status.idle":"2022-02-23T19:00:20.952012Z","shell.execute_reply.started":"2022-02-23T19:00:20.938721Z","shell.execute_reply":"2022-02-23T19:00:20.951141Z"}}},{"cell_type":"markdown","source":"## Math Functions\ncalled sumList(), meanList(), minMaxList(), and stdevList() to calculate the summation, mean, minimum, maximum, standard deviation of any given list. Each function has a list as an input, and returns the corresponding result (i.e., sum, mean, min, max, stdev, etc.). Please note: a) meanList() should use sumList() to calculate the summation of a list; b) stdevList() should use meanList() to calculate the mean value; c) minMaxList() should return both min and max values.","metadata":{}},{"cell_type":"code","source":"#Return the total:\ndef sumList(numbers):\n    count=0\n    for n in numbers:\n        count=count+n\n    total=round(count,2)\n    return total\n\n#Return the mean:\ndef meanList(numbers):\n    total=sumList(numbers)\n    mean=round(total/len(numbers),2)\n    return mean\n\n#Return the standard deviation:\ndef stdevList(mean):\n    var=0 #variance\n    for d in data:\n        n=d-mean\n        n2=n*n\n        var=var+n2\n    std=var/len(data)\n    std=round(std**0.5,2)\n    return std","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.113145Z","iopub.execute_input":"2022-03-02T22:13:52.113422Z","iopub.status.idle":"2022-03-02T22:13:52.120068Z","shell.execute_reply.started":"2022-03-02T22:13:52.113389Z","shell.execute_reply":"2022-03-02T22:13:52.118963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step One: View Data\nRead the csv file and display the data below.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nsFile=r'/kaggle/input/salary/salary.csv'\nsDF = pd.read_csv(sFile, header=None, names=['years', 'salary'])\nsDF","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.121538Z","iopub.execute_input":"2022-03-02T22:13:52.121886Z","iopub.status.idle":"2022-03-02T22:13:52.149699Z","shell.execute_reply.started":"2022-03-02T22:13:52.121857Z","shell.execute_reply":"2022-03-02T22:13:52.149103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step Two: Split Data\nFunction will be called train_test_split that will split the dataset List into a training set and a test based on 75% for training and 25% for testing. Normally, one can use `from sklearn.model_selection import train_test_split` to do this but in this case the train_test_split function will do this manually.","metadata":{}},{"cell_type":"code","source":"def train_test_split(aList, ratio=.25):\n    elements = len(aList)\n    middle = int(elements * ratio)\n    trainSet=[list_to_split[:middle]]\n    testSet=[list_to_split[middle:]]\n    return trainSet, testSet","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.150828Z","iopub.execute_input":"2022-03-02T22:13:52.151219Z","iopub.status.idle":"2022-03-02T22:13:52.156016Z","shell.execute_reply.started":"2022-03-02T22:13:52.151186Z","shell.execute_reply":"2022-03-02T22:13:52.155256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step Three: Calculate Variance\nCalculate covariance and variance from the training dataset. \n<br> Another function, coefficeints will find out the cofficients.\nSome premade math functions I made that will used are the following:<br>\n`\nmean=meanList(data)\nstdev=stdevList(mean)\n`\n","metadata":{}},{"cell_type":"code","source":"def covarianceList(x, y):\n    # Finding the mean of the series x and y\n    mean_x = meanList(x)\n    mean_y = meanList(y)\n    \n    # Subtracting mean from the individual elements\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n    \n    numerator = sum([sub_x[i]*sub_y[i] for i in range(len(sub_x))])\n    denominator = len(x)-1\n    cov = numerator/denominator\n    return cov\n\ndef varianceList(results):\n    # calculate mean\n    m = meanList(results)\n\n    # calculate variance using a list comprehension\n    var = sum((xi - m) ** 2 for xi in results) / len(results)\n    return var\n\ndef coefficeints():\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.157664Z","iopub.execute_input":"2022-03-02T22:13:52.158409Z","iopub.status.idle":"2022-03-02T22:13:52.169606Z","shell.execute_reply.started":"2022-03-02T22:13:52.158378Z","shell.execute_reply":"2022-03-02T22:13:52.168962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Print Function Results:","metadata":{}},{"cell_type":"code","source":"sDF=sDF.reset_index()\nx=sDF['years']\ny=sDF['salary']\n\n#COVARIANCE:\ncov=round(covarianceList(x,y),2)\nprint(\"The covariance is: \", cov)\n\n#VARIANCE:\nvar=round(varianceList(x),2)\nprint(\"The variance is: \", var)\n\n#COEFFICIENTS:\ncoef=coefficeints()\nprint(\"The coefficient is: \", coef)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.170736Z","iopub.execute_input":"2022-03-02T22:13:52.171654Z","iopub.status.idle":"2022-03-02T22:13:52.184902Z","shell.execute_reply.started":"2022-03-02T22:13:52.171595Z","shell.execute_reply":"2022-03-02T22:13:52.183917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step4) Calculate RMSE\nRoot Mean Squared Error (RMSE) is the standard deviation of the prediction errors. In simple terms, it tells an individual how far the predictions are away from the line of best fit. Here is the official formula below: <br>\n![image.png](attachment:ddc3c54b-03b2-450f-9936-e684bb7ce4af.png)\n\nΣ = summation (“add up”) <br>\n(zfi – Zoi)2 = differences, squared <br>\nN = sample size.\n\nIn English, one must do the following to get the RMSE:\n1. Squaring the residuals.\n2. Finding the average of the residuals.\n3. Taking the square root of the result.","metadata":{},"attachments":{"ddc3c54b-03b2-450f-9936-e684bb7ce4af.png":{"image/png":"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"}}},{"cell_type":"code","source":"def evalRMSE(testResultsList):\n    \n    return rmse","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.185933Z","iopub.execute_input":"2022-03-02T22:13:52.186152Z","iopub.status.idle":"2022-03-02T22:13:52.198002Z","shell.execute_reply.started":"2022-03-02T22:13:52.186126Z","shell.execute_reply":"2022-03-02T22:13:52.197172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Linear Regression with imports\nThis is the same concept but doing the linear regression with sklearn as an import. One of the most basic and used types of predictive modeling is linear regression. Linear regression can help find the strength and effect indepedent variables have on dependent variables. I will verify the results using sklearn imports, instead of doing it by hand.\nhttps://towardsdatascience.com/simple-linear-regression-model-using-python-machine-learning-eab7924d18b4","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\n\nx=sDF[['years']]\nx=sDF[['salary']]\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=13)\n\n#Fit and predict:\nlrModel = LinearRegression()\nlrModel.fit(X_train, y_train)\nlrPredict = lrModel.predict(X_test)\n\n#Linear Metrics:\nr2 = r2_score(y_test, lrPredict).round(4) \nprint(\"Linear regression r2 score: \", r2)\n\n#PRINT COEFFICIENT:\nlrModel.coef_  \n\n#PRINT MEAN SQUARED ERROR:\nmetrics.mean_absolute_error(y_test, lrPredict)\nnp.sqrt(metrics.mean_squared_error(y_test, lrPredict))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:18:00.336874Z","iopub.execute_input":"2022-03-02T22:18:00.337165Z","iopub.status.idle":"2022-03-02T22:18:00.360257Z","shell.execute_reply.started":"2022-03-02T22:18:00.337138Z","shell.execute_reply":"2022-03-02T22:18:00.359617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Data\nThe graph clearly shows a trend that salary and years are correlated. Meaning, the more years experience, the salary tends to be higher. ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nx=sDF['years']\ny=sDF['salary']\nplt.scatter(x,y)\nplt.title(\"Years versus Salary\")\nplt.xlabel('Years')\nplt.ylabel('Salary')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T22:13:52.230409Z","iopub.status.idle":"2022-03-02T22:13:52.230774Z","shell.execute_reply.started":"2022-03-02T22:13:52.230607Z","shell.execute_reply":"2022-03-02T22:13:52.230631Z"},"trusted":true},"execution_count":null,"outputs":[]}]}