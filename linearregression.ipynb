{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Analyze Salary with Linear Regression\nPython Automation; Scott Schmidt; Illinois State University\n\n## Introduction\n1. The dataset will have two columns of data which are years and salary. \n2. Split the data using 75% training and 25% testing. \n3. Calculate Covariance and Variance to find the coefficients. \n4. Evaluate the model performance using Root Mean Square Error (RMSE).\n\nThis assignment is valuable coming from someone who passed a first round Python Data Science interview at a fortune100. This verifies that one understands all the imports by doing them manually by hand. Often times, imports can weaken ones understanding because the human will not understand the entire process.","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:00:20.938476Z","iopub.execute_input":"2022-02-23T19:00:20.938748Z","iopub.status.idle":"2022-02-23T19:00:20.952012Z","shell.execute_reply.started":"2022-02-23T19:00:20.938721Z","shell.execute_reply":"2022-02-23T19:00:20.951141Z"}}},{"cell_type":"markdown","source":"## Math Functions\ncalled sumList(), meanList(), minMaxList(), and stdevList() to calculate the summation, mean, minimum, maximum, standard deviation of any given list. Each function has a list as an input, and returns the corresponding result (i.e., sum, mean, min, max, stdev, etc.). Please note: a) meanList() should use sumList() to calculate the summation of a list; b) stdevList() should use meanList() to calculate the mean value; c) minMaxList() should return both min and max values.","metadata":{}},{"cell_type":"code","source":"#Return the total:\ndef sumList(numbers):\n    count=0\n    for n in numbers:\n        count=count+float(n)\n    total=round(count,2)\n    return total\n\n#Return the mean:\ndef meanList(numbers):\n    total=sumList(numbers)\n    mean=round(total/len(numbers),2)\n    return mean\n\n#Return the standard deviation:\ndef stdevList(mean):\n    var=0 #variance\n    for d in data:\n        n=d-mean\n        n2=n*n\n        var=var+n2\n    std=var/len(data)\n    std=round(std**0.5,2)\n    return std","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:22.970931Z","iopub.execute_input":"2022-03-07T03:59:22.971195Z","iopub.status.idle":"2022-03-07T03:59:22.980227Z","shell.execute_reply.started":"2022-03-07T03:59:22.971167Z","shell.execute_reply":"2022-03-07T03:59:22.979401Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Step One: View Data\nRead the csv file and display the data below.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nsFile=r'/kaggle/input/salary/salary.csv'\nsDF = pd.read_csv(sFile, header=None, names=['years', 'salary'])\nsDF","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:22.981681Z","iopub.execute_input":"2022-03-07T03:59:22.981952Z","iopub.status.idle":"2022-03-07T03:59:24.355439Z","shell.execute_reply.started":"2022-03-07T03:59:22.981922Z","shell.execute_reply":"2022-03-07T03:59:24.354560Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Step Two: Split Data\nFunction will be called train_test_split that will split the dataset List into a training set and a test based on 75% for training and 25% for testing. Normally, one can use `from sklearn.model_selection import train_test_split` to do this but in this case the train_test_split function will do this manually.","metadata":{}},{"cell_type":"code","source":"def train_test_split(aList, ratio=.25):\n    elements = len(aList)\n    middle = int(elements * ratio)\n    trainSet=[list_to_split[:middle]]\n    testSet=[list_to_split[middle:]]\n    return trainSet, testSet","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.356549Z","iopub.execute_input":"2022-03-07T03:59:24.356759Z","iopub.status.idle":"2022-03-07T03:59:24.363228Z","shell.execute_reply.started":"2022-03-07T03:59:24.356734Z","shell.execute_reply":"2022-03-07T03:59:24.361375Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Step Three: Calculate Variance\nCalculate covariance and variance from the training dataset. \n<br> Another function, coefficeints will find out the cofficients.\nSome premade math functions I made that will used are the following:<br>\n`\nmean=meanList(data)\nstdev=stdevList(mean)\n`\n","metadata":{}},{"cell_type":"code","source":"# Calculate the variance of a list of numbers:\ndef varianceList(aList):\n    # calculate mean\n    m = meanList(aList)\n\n    # calculate variance using a list comprehension\n    var = sum((xi - m) ** 2 for xi in aList) / len(aList)\n    return var\n\n#Calculate the covariance of two lists of numbers:\ndef covarianceList(x, y):\n    # Finding the mean of the series x and y\n    mean_x = meanList(x)\n    mean_y = meanList(y)\n    \n    # Subtracting mean from the individual elements\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n    \n    numerator = sum([sub_x[i]*sub_y[i] for i in range(len(sub_x))])\n    denominator = len(x)-1\n    cov = numerator/denominator\n    return cov","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.365501Z","iopub.execute_input":"2022-03-07T03:59:24.365804Z","iopub.status.idle":"2022-03-07T03:59:24.380922Z","shell.execute_reply.started":"2022-03-07T03:59:24.365777Z","shell.execute_reply":"2022-03-07T03:59:24.379373Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Calculate Coefficients\nCalculate the {w}_{0} and {w}_{1} values <br>\nHint: Calculate the covariance of two lists of numbers: <br>\nThe input is a list with each item a list   [x, y] <br>","metadata":{}},{"cell_type":"code","source":"def coefficeints(trainingDatasetList):\n    x=list(trainingDatasetList[0])\n    y=list(trainingDatasetList[1])\n\n    w1 = covarianceList(x, y) / float(varianceList(x))\n \n    # Coefficient W0 = mean of y_readings - ( W1 * the mean of the x_readings )\n    w0 = meanList(y) - (w1 * meanList(x))\n    return w0, w1","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.382726Z","iopub.execute_input":"2022-03-07T03:59:24.383552Z","iopub.status.idle":"2022-03-07T03:59:24.403649Z","shell.execute_reply.started":"2022-03-07T03:59:24.383507Z","shell.execute_reply":"2022-03-07T03:59:24.402169Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"##### Print Function Results:","metadata":{}},{"cell_type":"code","source":"sDF=sDF.reset_index()\nx=sDF['years']\ny=sDF['salary']\nx=list(x)\ny=list(y)\n\n#COVARIANCE:\ncov=round(covarianceList(x,y),2)\nprint(\"The covariance is: \", cov)\n\n#VARIANCE:\nvar=round(varianceList(x),2)\nprint(\"The variance is: \", var)\n\n#COEFFICIENTS:\ntrainingDatasetList= [x, y]\ncoef=coefficeints(trainingDatasetList)\nprint(\"The coefficients are: \", coef)\n\nw0=coef[0]\nw1=coef[1]\nprint(w0)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.405450Z","iopub.execute_input":"2022-03-07T03:59:24.405692Z","iopub.status.idle":"2022-03-07T03:59:24.433221Z","shell.execute_reply.started":"2022-03-07T03:59:24.405663Z","shell.execute_reply":"2022-03-07T03:59:24.432296Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## y = w0 + w1*x1\n`\nx_new = np.array([0, 1, 2, 3])\ny_prediction = lr.intercept_ + x_new*lr.coef_[0]\nlr.predict(x_new.reshape(-1,1))\n`\n\nw0 and w1 are the two coefficients, where w0 is the intercept (of the y-axis), and w1 is the slope of the line. w1 shows the impact of the independent variable x1 on y. For example, when w1 = 0, there’s no impact of x1 on y since (0*x1 = 0).\n\nIn simple terms, linear regression is an algorithm that finds the best values of w0 and w1 to fit the training dataset.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step4) Calculate RMSE\nRoot Mean Squared Error (RMSE) is the standard deviation of the prediction errors. In simple terms, it tells an individual how far the predictions are away from the line of best fit. Here is the official formula below: <br>\n![image.png](attachment:ddc3c54b-03b2-450f-9936-e684bb7ce4af.png)\n\nΣ = summation (“add up”) <br>\n(zfi – Zoi)2 = differences, squared <br>\nN = sample size.\n\nSpecifically, one must do the following to get the RMSE:\n1. Squaring the residuals.\n2. Finding the average of the residuals.\n3. Taking the square root of the result.","metadata":{},"attachments":{"ddc3c54b-03b2-450f-9936-e684bb7ce4af.png":{"image/png":"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"}}},{"cell_type":"code","source":"def evalRMSE(testResultsList):\n    rmse= np.sqrt(((predictions - targets) ** 2).mean())\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.434529Z","iopub.execute_input":"2022-03-07T03:59:24.435437Z","iopub.status.idle":"2022-03-07T03:59:24.447646Z","shell.execute_reply.started":"2022-03-07T03:59:24.435380Z","shell.execute_reply":"2022-03-07T03:59:24.446897Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## References\n1. https://www.urbanpro.com/machine-learning/linear-regression-without-any-libraries\n2. https://dataaspirant.com/simple-linear-regression-python-without-any-machine-learning-libraries/\n3. https://github.com/Rajath1995/Linear-Regression-without-Scikit-Learn/blob/master/P1%20Regression%20-%20Group%201.ipynb","metadata":{}},{"cell_type":"markdown","source":"## Simple Linear Regression with imports\nThis is the same concept but doing the linear regression with sklearn as an import. One of the most basic and used types of predictive modeling is linear regression. Linear regression can help find the strength and effect indepedent variables have on dependent variables. I will verify the results using sklearn imports, instead of doing it by hand.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import r2_score\n\nx=sDF[['years']]\nx=sDF[['salary']]\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=13)\n\n#Fit and predict:\nlrModel = LinearRegression()\nlrModel.fit(X_train, y_train)\nlrPredict = lrModel.predict(X_test)\n\n#Linear Metrics:\nr2 = r2_score(y_test, lrPredict).round(4) \nprint(\"Linear regression r2 score: \", r2)\n\n#PRINT COEFFICIENT:\nlrCoef=lrModel.coef_  \nprint(\"Linear coef: \", lrCoef)\n\n#PRINT MEAN SQUARED ERROR:\nlrMSE=np.sqrt(metrics.mean_squared_error(y_test, lrPredict))\nprint(\"Linear regression MSE: \", lrMSE)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.449401Z","iopub.execute_input":"2022-03-07T03:59:24.449976Z","iopub.status.idle":"2022-03-07T03:59:24.595804Z","shell.execute_reply.started":"2022-03-07T03:59:24.449911Z","shell.execute_reply":"2022-03-07T03:59:24.594898Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Plot Data\nThe graph clearly shows a trend that salary and years are correlated. Meaning, the more years experience, the salary tends to be higher. ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nx=sDF['years']\ny=sDF['salary']\nplt.scatter(x,y)\nplt.title(\"Years versus Salary\")\nplt.xlabel('Years')\nplt.ylabel('Salary')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T03:59:24.596951Z","iopub.execute_input":"2022-03-07T03:59:24.597161Z","iopub.status.idle":"2022-03-07T03:59:24.842698Z","shell.execute_reply.started":"2022-03-07T03:59:24.597136Z","shell.execute_reply":"2022-03-07T03:59:24.841735Z"},"trusted":true},"execution_count":10,"outputs":[]}]}